{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Resource Monitoring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook visualizes data from a BQ dataset that holds workflow resource usage monitoring data. Please refer to the Readme for what data are collected and how they are collected. The notebook will produce three plots, one PDF and two interactive HTML reports.\n",
    "\n",
    "The following need to be provided to the notebook: \n",
    "- workflow and sub-workflow IDs\n",
    "- workflow execution dates\n",
    "- where to store the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "import concurrent.futures\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from math import isnan, pi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import bokeh.io \n",
    "from bokeh import *\n",
    "from bokeh.io import output_notebook, output_file, show \n",
    "from bokeh.models import Span, HoverTool, Title, Label, Legend, LegendItem, ColumnDataSource, Div\n",
    "from bokeh.models.widgets import DataTable, DateFormatter, TableColumn\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import column, layout\n",
    "from bokeh.palettes import Category20c\n",
    "from bokeh.transform import cumsum\n",
    "import seaborn as sns\n",
    "\n",
    "import google.auth\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query BQ database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QueryBQToMonitor class contains the query scripts for the three different BQ tables (Metrics, Runtime, Cromwell Metadata). Its takes in a workflow ID and IDs of subworkflows (if any) and estimated dates when the job was submitted and successfully finished. It uses these parameters to query the BQ tables and produces a pandas datafram. \n",
    "\n",
    "By default the the queury searches in the `broad-dsde-methods` BQ project. If needed change this to the project the workflow was run on or the project you expect the monitoirng tables to be saved in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     30,
     83,
     121
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QueryBQToMonitor:\n",
    "    \n",
    "    def __init__(self, workflowids, days_back_upper_bound, days_back_lower_bound):\n",
    "        \n",
    "        self.logger = logging.getLogger()\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "        h = logging.StreamHandler(sys.stderr)\n",
    "        h.flush = sys.stderr.flush\n",
    "        self.logger.addHandler(h)\n",
    "        \n",
    "        self.formated_workflow_ids = ','.join(workflow_ids)\n",
    "        \n",
    "        self.days_back_upper_bound = days_back_upper_bound\n",
    "        self.days_back_lower_bound = days_back_lower_bound\n",
    "        \n",
    "        # Explicitly create a credentials object. This allows you to use the same\n",
    "        # credentials for both the BigQuery and BigQuery Storage clients, avoiding\n",
    "        # unnecessary API calls to fetch duplicate authentication tokens.\n",
    "        credentials, project_id = google.auth.default(\n",
    "            scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "        )\n",
    "\n",
    "        # Make clients.\n",
    "        self.bq_client = bigquery.Client(credentials=credentials, project=project_id )\n",
    "        \n",
    "    def query(self):\n",
    "        self._get_runtime_and_metadata()\n",
    "        self._get_metrics()\n",
    "    \n",
    "    def _get_runtime_and_metadata(self):\n",
    "        \n",
    "        self._fetch_runtime()\n",
    "        self._fetch_metadata()\n",
    "        \n",
    "        runtime_nrow, runtime_ncol = self.runtime.shape\n",
    "        meta_nrow, meta_ncol = self.metadata.shape\n",
    "        \n",
    "        # basic QC\n",
    "        if (meta_nrow != runtime_nrow):\n",
    "            self.logger.warning('Metadata and runtime number of rows are different. You might want to check.')\n",
    "        summary_msg = f\"Nrows of runtime: {runtime_nrow}, Ncols of runtime: {runtime_ncol}, \\nNrows of meta: {meta_nrow}, Ncols of meta: {meta_ncol}\"\n",
    "        self.logger.info(summary_msg)\n",
    "        \n",
    "        # merge the two\n",
    "        self.metadata_runtime = pd.merge(self.metadata, self.runtime, left_on='meta_instance_name', right_on='runtime_instance_name')\n",
    "        print()\n",
    "        self.metadata_runtime.runtime_task_call_name.describe()\n",
    "\n",
    "    def _fetch_runtime(self):\n",
    "        # query runtime data\n",
    "        runtime_sql = f\"\"\"\n",
    "\n",
    "        SELECT\n",
    "\n",
    "          runtime.attempt AS runtime_attempt,\n",
    "          runtime.cpu_count AS runtime_cpu_count,\n",
    "          runtime.cpu_platform AS runtime_cpu_platform,\n",
    "          runtime.disk_mounts AS runtime_disk_mounts,\n",
    "          runtime.disk_total_gb AS runtime_disk_total_gb,\n",
    "          runtime.instance_id AS runtime_instance_id,\n",
    "          runtime.instance_name AS runtime_instance_name,\n",
    "          runtime.mem_total_gb AS runtime_mem_total_gb,\n",
    "          runtime.preemptible AS runtime_preemptible,\n",
    "          runtime.project_id AS runtime_project_id,\n",
    "          runtime.shard AS runtime_shard,\n",
    "          runtime.start_time AS runtime_start_time,\n",
    "          runtime.task_call_name AS runtime_task_call_name,\n",
    "          runtime.workflow_id AS runtime_workflow_id,\n",
    "          runtime.zone AS runtime_zone\n",
    "\n",
    "        FROM\n",
    "          `broad-dsde-methods.cromwell_monitoring.runtime`  runtime \n",
    "\n",
    "        WHERE\n",
    "              DATE(runtime.start_time) >= DATE_SUB(CURRENT_DATE(), INTERVAL {self.days_back_upper_bound} DAY)\n",
    "          AND DATE(runtime.start_time) <= DATE_SUB(CURRENT_DATE(), INTERVAL {self.days_back_lower_bound} DAY)\n",
    "\n",
    "          AND runtime.workflow_id IN ({self.formated_workflow_ids})    \n",
    "        \"\"\"\n",
    "        self.runtime = self.bq_client.query(query = runtime_sql).to_dataframe()\n",
    "        self.logger.info(\"Fetched runtime table.\")\n",
    "    \n",
    "    def _fetch_metadata(self):\n",
    "        # query metadata table\n",
    "        metadata_sql = f\"\"\"\n",
    "\n",
    "        SELECT\n",
    "          metadata.attempt AS meta_attempt,\n",
    "          metadata.cpu_count AS meta_cpu,\n",
    "          metadata.disk_mounts AS meta_disk_mounts,\n",
    "          metadata.disk_total_gb AS meta_disk_total_gb,\n",
    "          metadata.disk_types AS meta_disk_types,\n",
    "          metadata.docker_image AS meta_docker_image,\n",
    "          metadata.end_time AS meta_end_time,\n",
    "          metadata.execution_status AS meta_execution_status,\n",
    "          metadata.inputs AS meta_inputs,\n",
    "          metadata.instance_name AS meta_instance_name,\n",
    "          metadata.mem_total_gb AS meta_mem_total_gb,\n",
    "          metadata.preemptible AS meta_preemptible,\n",
    "          metadata.project_id AS meta_project_id,\n",
    "          metadata.shard AS meta_shard,\n",
    "          metadata.start_time AS meta_start_time,\n",
    "          metadata.task_call_name AS meta_task_call_name,\n",
    "          metadata.workflow_id AS meta_workflow_id,\n",
    "          metadata.workflow_name AS meta_workflow_name,\n",
    "          metadata.zone AS meta_zone,\n",
    "          TIMESTAMP_DIFF(metadata.end_time, metadata.start_time, SECOND) meta_duration_sec\n",
    "\n",
    "        FROM\n",
    "          `broad-dsde-methods.cromwell_monitoring.metadata` metadata\n",
    "\n",
    "        WHERE\n",
    "              DATE(metadata.start_time) >= DATE_SUB(CURRENT_DATE(), INTERVAL {self.days_back_upper_bound} DAY)\n",
    "          AND DATE(metadata.start_time) <= DATE_SUB(CURRENT_DATE(), INTERVAL {self.days_back_lower_bound} DAY)\n",
    "\n",
    "          AND metadata.workflow_id IN ({self.formated_workflow_ids})    \n",
    "        \"\"\"\n",
    "        self.metadata = self.bq_client.query(query = metadata_sql).to_dataframe()\n",
    "        self.logger.info(\"Fetched metadata table\")\n",
    "            \n",
    "    def _get_metrics(self):\n",
    "        \n",
    "        b = datetime.datetime.now()\n",
    "        start_time = b.strftime(\"%H:%M:%S\")\n",
    "        self.logger.info(f\"Started querying metrics on {start_time}.\")\n",
    "        # provision jobs\n",
    "        instance_ids = list(self.metadata_runtime.runtime_instance_id.unique())\n",
    "        n = 8 # magic number based on experience\n",
    "        cap = len(instance_ids) // 8\n",
    "\n",
    "        ids_pool = dict()\n",
    "        jobs_pool = dict()\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "\n",
    "            for i in range(n+1):\n",
    "                start = i * cap\n",
    "                if (i != n):\n",
    "                    end = (i+1) * cap - 1\n",
    "                else:\n",
    "                    end = len(instance_ids)\n",
    "                ids_pool[i] = instance_ids[start:end]\n",
    "                jobs_pool[i] = executor.submit(self._fetch_metrics_on_vms_batch, ids_pool[i])\n",
    "\n",
    "\n",
    "        results_pool = dict()\n",
    "        for i in range(n+1):\n",
    "            results_pool[i] = jobs_pool[i].result()\n",
    "        \n",
    "        \n",
    "        f = datetime.datetime.now()\n",
    "        finish_time = f.strftime(\"%H:%M:%S\")\n",
    "        pf = f - b\n",
    "        s = pf.seconds\n",
    "        hours, remainder = divmod(s, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        elapse = '{:02}:{:02}:{:02}'.format(int(hours), int(minutes), int(seconds))\n",
    "        self.logger.info(f\"Finished on {finish_time}.\")\n",
    "        self.logger.info(f\"Totalling {elapse}.\")\n",
    "       \n",
    "        \n",
    "        l = list(results_pool.values())            \n",
    "        self.metrics = pd.concat(l)\n",
    "        \n",
    "        # QC\n",
    "        retries = 0\n",
    "        d = set(self.metadata_runtime.runtime_instance_id.unique()) - set(self.metrics.metrics_instance_id.unique())\n",
    "        while( (not d) and 10>retries ):\n",
    "            self.logger.info(f\"Retrieving metrics info on leftovers: {d}\")\n",
    "            left_over = self._fetch_metrics_on_vms_batch(d)\n",
    "            if (not left_over.empty):\n",
    "                self.metrics = pd.concat([self.metrics, left_over], axis=0)\n",
    "            d = set(self.metadata_runtime.runtime_instance_id.unique()) - set(self.metrics.metrics_instance_id.unique())\n",
    "            retries += 1\n",
    "        if (0!=d):\n",
    "            self.logger.warning(f\"Not all VMs provisioned have their metrics sent over ({d} didn't).\")\n",
    "\n",
    "    def _fetch_metrics_on_vms_batch(self, vm_instance_ids):\n",
    "        ids_string = ', '.join(map(str, vm_instance_ids))\n",
    "        metrics_sql = f\"\"\"\n",
    "\n",
    "        SELECT\n",
    "\n",
    "          metrics.cpu_used_percent AS metrics_cpu_used_percent,\n",
    "          metrics.disk_read_iops AS metrics_disk_read_iops,\n",
    "          metrics.disk_used_gb AS metrics_disk_used_gb,\n",
    "          metrics.disk_write_iops AS metrics_disk_write_iops,\n",
    "          metrics.instance_id AS metrics_instance_id,\n",
    "          metrics.mem_used_gb AS metrics_mem_used_gb,\n",
    "          metrics.timestamp AS metrics_timestamp\n",
    "\n",
    "        FROM\n",
    "          `broad-dsde-methods.cromwell_monitoring.metrics`  metrics\n",
    "\n",
    "        WHERE\n",
    "\n",
    "              DATE(metrics.timestamp) >= DATE_SUB(CURRENT_DATE(), INTERVAL {self.days_back_upper_bound} DAY)\n",
    "          AND DATE(metrics.timestamp) <= DATE_SUB(CURRENT_DATE(), INTERVAL {self.days_back_lower_bound} DAY)\n",
    "          AND metrics.instance_id IN ({ids_string})\n",
    "\n",
    "        \"\"\"\n",
    "        return self.bq_client.query(metrics_sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the following variables:\n",
    "1. workflow_ids = Workflow id for the executed job and any subworkflows ids that maybe be available. \n",
    "2. days_back_upper_bound = The number of days back from today that the workflow started.\n",
    "3. days_back_lower_bound = The number of days back from today that the workflow ended.\n",
    "\n",
    "Example:\n",
    "```\n",
    "workflow_ids= [\"\\\"a0a92771-c925-49b4-887e-877deeacc742\\\"\",      # main workflow id\n",
    "               \"\\\"9837e566-0f37-444b-be3e-a135616f4c6e\\\"\"]      # sub workflow id\n",
    "days_back_upper_bound = 85\n",
    "days_back_lower_bound = 80\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Control 05/09/2020\n",
    "workflow_ids= # ADD WORKFLOW ID\n",
    "PARENT_WORKFLOW_ID = workflow_ids[0].strip('\"')\n",
    "days_back_upper_bound = # ADD INTEGER\n",
    "days_back_lower_bound = # ADD INTEGER\n",
    "df_monitoring = QueryBQToMonitor(workflow_ids, days_back_upper_bound, days_back_lower_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have two scenarios\n",
    "1) Perform a fresh query and save query results locally to be used in another session.\n",
    "2) Import local query results that was saved from a earlier session. \n",
    "\n",
    "### Scenario 1\n",
    "The next cell uses uses the QueryBQToMonitor class to query the BQ database using the variables that were provided for workflow_id and dates. (If data is saved locally you may skip this cell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Query the BQ database\n",
    "df_monitoring.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After quering the BQ database, you may want to save the data locally to avoid the cost of querying the BQ again in the future. The next cell will save the pandas dataframe into a pickle file. (If data is saved locally you may skip this cell.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Saves dataframe locally in pickle format\n",
    "df_monitoring.metrics.to_pickle(PARENT_WORKFLOW_ID + '_metrics_resource_monitoring.pkl')\n",
    "df_monitoring.metadata_runtime.to_pickle(PARENT_WORKFLOW_ID + '_metadata_runtime_resource_monitoring.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2\n",
    "If resource data is saved locally from a prevous run of this job then you will want to import them instead of reruning the BQ query above. Run the next cell to import the pickle files saved from a previous session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import datafram locally\n",
    "if path.exists(PARENT_WORKFLOW_ID + '_metrics_resource_monitoring.pkl'):\n",
    "    print('Loading metrics from existing pickel file')\n",
    "    df_monitoring.metrics = pd.read_pickle(PARENT_WORKFLOW_ID + '_metrics_resource_monitoring.pkl') \n",
    "else:\n",
    "    print('No metrics from existing pickel file ' + PARENT_WORKFLOW_ID + '_metrics_resource_monitoring.pkl')\n",
    "if path.exists(PARENT_WORKFLOW_ID + '_metadata_runtime_resource_monitoring.pkl'):\n",
    "    print('Loading metadata and runtime from existing pkl')\n",
    "    df_monitoring.metadata_runtime = pd.read_pickle(PARENT_WORKFLOW_ID + '_metadata_runtime_resource_monitoring.pkl') \n",
    "else:\n",
    "    print('No metadata and runtime dataframe from existing pikel file ' + PARENT_WORKFLOW_ID + '_metadata_runtime_resource_monitoring.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the tables obtained from scenario 1 or 2 the next cell will create an addtional monitoring dataframe table that will be used later during ploting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adds runtime columns to metrics needed for ploting\n",
    "df_monitoring.metrics_runtime = pd.merge(df_monitoring.metrics,\n",
    "                                df_monitoring.metadata_runtime[['runtime_workflow_id',\n",
    "                                                               'runtime_task_call_name',\n",
    "                                                               'runtime_shard',\n",
    "                                                               'runtime_instance_id',\n",
    "                                                               'meta_duration_sec']], \n",
    "                                left_on='metrics_instance_id', right_on='runtime_instance_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and Plot Data\n",
    "We will now begin extracting and plotting data from the resource monitoring dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow duration Summary\n",
    "The next few cells will obtain and plot the workflow duration summary. Consisting of a table and plot of the workflow duration per task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get workflow total duration in sec\n",
    "latest_end_datetime = max(df_monitoring.metadata_runtime['meta_end_time'])\n",
    "earliest_start_datetime = min(df_monitoring.metadata_runtime['meta_start_time'])\n",
    "workflow_duration = round(datetime.timedelta.total_seconds(latest_end_datetime - earliest_start_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get an array of task names in workflow\n",
    "TaskNames = df_monitoring.metrics_runtime.runtime_task_call_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_info_per_task(task_name,df):\n",
    "    df_task = df.loc[(df['runtime_task_call_name'] == task_name)]\n",
    "    latest_end_datetime = max(df_task['metrics_timestamp'])\n",
    "    earliest_start_datetime = min(df_task['metrics_timestamp'])\n",
    "    task_duration = round(datetime.timedelta.total_seconds(latest_end_datetime - earliest_start_datetime))\n",
    "    \n",
    "    shard_count = len(df_task.runtime_shard.unique())\n",
    "    return task_duration, shard_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get task duration and shard count using the get_info_per_task def per task in the workflow\n",
    "task_summary_dict = {}\n",
    "for task in TaskNames:\n",
    "    task_summary_dict[task] = get_info_per_task(task,df_monitoring.metrics_runtime)\n",
    "\n",
    "#create new dic, for each element in task_summary_dict, get the first element in tuple and add it to the new dict\n",
    "task_summary_duration = {}\n",
    "for task in task_summary_dict:\n",
    "    task_summary_duration[task] = task_summary_dict[task][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn task_summary to datafram in order for it to be easily turned into a bokeh table\n",
    "df_task_summary = pd.DataFrame.from_dict(task_summary_dict)\n",
    "df_task_summary_T = df_task_summary.T.rename_axis('Tasks').reset_index()\n",
    "df_task_summary_named = df_task_summary_T.rename(columns={0: \"Duration\", 1: \"Shards\"},errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_pie(data_dict, title):\n",
    "    output_notebook()\n",
    "    x = data_dict\n",
    "\n",
    "    data = pd.Series(x).reset_index(name='value').rename(columns={'index':'task'})\n",
    "    data['angle'] = data['value']/data['value'].sum() * 2*pi\n",
    "    data['color'] = Category20c[len(x)]\n",
    "    \n",
    "    p = figure(plot_height=350, \n",
    "               title=title, \n",
    "               toolbar_location=None,\n",
    "               tools=\"hover\", \n",
    "               tooltips=(\"@task: @value\"), \n",
    "               x_range=(-0.5, 1.0))\n",
    "\n",
    "    p.wedge(x=0, y=1, radius=0.4,\n",
    "            start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "            line_color=\"white\", fill_color='color', legend='task', source=data)\n",
    "\n",
    "    p.axis.axis_label=None\n",
    "    p.axis.visible=False\n",
    "    p.grid.grid_line_color = None\n",
    "\n",
    "    #show(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Place any outputs from bokeh into the following file\n",
    "output_file(\"{}_workflow_summary.html\".format(PARENT_WORKFLOW_ID))\n",
    "\n",
    "#Get Column names from pandas datafram\n",
    "Columns = [TableColumn(field=Ci, title=Ci) for Ci in df_task_summary_named.columns] # bokeh columns\n",
    "\n",
    "#Create bokeh datatables using pandas dataframe and column names\n",
    "task_summary_table = DataTable(columns=Columns, source=ColumnDataSource(df_task_summary_named)) # bokeh table\n",
    "\n",
    "#Create pie plot for workflow duration\n",
    "workflow_duration_pie = plot_pie(task_summary_duration, \"Workflow Duration in Seconds\")\n",
    "\n",
    "#Divs\n",
    "workflow_title_div = Div(text=\"<h1>{} <br> Workflow Summary</h2>\".format(PARENT_WORKFLOW_ID),width=600, height=50)\n",
    "workflow_duration_div = Div(text=\"The workflow took {} seconds to complete.\".format(workflow_duration),width=300, height=25)\n",
    "\n",
    "# Place the outputs from bokeh in this layout, which will be the layout in html file _workflow_summary.html\n",
    "show(layout([\n",
    "            [workflow_title_div],\n",
    "            [workflow_duration_div],\n",
    "            [Div(text=\"<h3>Workflow Summary Table</h3>\",width=300, height=25)],\n",
    "            [task_summary_table],\n",
    "            [workflow_duration_pie]\n",
    "            ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task sharded summary and task detailed summary\n",
    "The next few cells will extract and plot \n",
    "- A task shard summary plot html file. This used for any scattered tasks, providing a high level view of resource usage for each shard in a task (*_shard_summary.html)\n",
    "- A detailed resource usage plot per task, This were the resource usage over the course of time are displayed for each task.(_resource_monitoring.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_of_string(x):\n",
    "    xfloat = np.array(x).astype(np.float)\n",
    "    return np.nanmean(xfloat)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_1st_disk_usage(x):\n",
    "    xfloat = np.array(x).astype(np.float)\n",
    "    return xfloat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_line(task_name, \n",
    "              shard, \n",
    "              task_shard_duration, \n",
    "              df_timestamp, \n",
    "              x_value,\n",
    "              resource_name,\n",
    "              obtained_resource,\n",
    "              requested_resource,\n",
    "              y_label,\n",
    "              x_label,t):\n",
    "        \n",
    "    if t==true: {plt.title(\"Task Name: \" + task_name + \" Shard: \" + str(shard) + \" Duration: \" +  str(task_shard_duration), fontsize=20)}\n",
    "    plt.plot(df_timestamp, x_value, label='{} Used'.format(resource_name))\n",
    "    plt.plot([], [], ' ', label='Obtained {}: {}' .format(resource_name, obtained_resource))\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(1.20, 0.8), shadow=True, ncol=1)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    plt2 = plt.twiny()\n",
    "    plt2.set_xlim(0, task_shard_duration)\n",
    "    plt2.set_xlabel(\"Duration Time\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_bar(x_value, y_value, chart_title, y_label,x_label):\n",
    "    # Needed in every cell to show plots in notebook\n",
    "    output_notebook()\n",
    "\n",
    "    #what to display when hovering\n",
    "    TOOLTIPS = [(x_label,' @x'),(y_label,' @top')]\n",
    "\n",
    "    #plot attributes\n",
    "    p = figure(x_range = x_value, \n",
    "               plot_height = 350, \n",
    "               sizing_mode = \"scale_width\", \n",
    "               title = chart_title,\n",
    "               toolbar_location = \"left\", \n",
    "               tooltips = TOOLTIPS) \n",
    "\n",
    "    #plot \n",
    "    p.vbar(x=x_value, top=y_value, width=0.9)\n",
    "\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.y_range.start = 0\n",
    "\n",
    "    # orient x labels vertically\n",
    "    p.xaxis.major_label_orientation = \"vertical\"\n",
    "    \n",
    "    # axis titles\n",
    "    p.xaxis.axis_label = x_label\n",
    "    p.yaxis.axis_label = y_label\n",
    "    \n",
    "    #Add the Mean horizontal line\n",
    "    p.ray(x=[0],y=[round(statistics.mean(y_value),1)],length=len(x_value), color='red', angle=0, legend=\"Mean: \"+str(round(statistics.mean(y_value),1)))\n",
    "\n",
    "    #show(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_violin(x_value, y_value, chart_title, y_label, x_label):\n",
    "    output_notebook()\n",
    "    #set plot size\n",
    "    #plt.rcParams[\"figure.figsize\"] = (7, 7)\n",
    "    #plt.figure(figsize=(7,7))\n",
    "    \n",
    "    #create df using array of values\n",
    "    df = pd.DataFrame(dict(Resource_Usage=y_value, Shard_Index=x_value))\n",
    "    \n",
    "    #plot styling\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    #plot values\n",
    "    ax = sns.violinplot(y=df[\"Resource_Usage\"], figsize=(7,7))\n",
    "    \n",
    "    #set plot lables\n",
    "    ax.set(xlabel='Shards', ylabel=y_label, title=chart_title)\n",
    "    \n",
    "    #return(plt.show())\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outliers(shards, resource_value, resource_label):\n",
    "    df = pd.DataFrame(dict(Resource_Usage=resource_value, Shard_Index=shards))\n",
    "\n",
    "    # find the quartiles and IQR \n",
    "    q1 = df.Resource_Usage.quantile(q=0.25)\n",
    "    q2 = df.Resource_Usage.quantile(q=0.5)\n",
    "    q3 = df.Resource_Usage.quantile(q=0.75)\n",
    "    iqr = q3 - q1\n",
    "    upper = q3 + 1.5*iqr\n",
    "    lower = q1 - 1.5*iqr\n",
    "    \n",
    "    upper_outliers = df[df.Resource_Usage > upper]\n",
    "    lower_outliers = df[df.Resource_Usage < lower]\n",
    "    \n",
    "    upper_outliers = upper_outliers.rename(columns={\"Resource_Usage\": resource_label})\n",
    "    lower_outliers = lower_outliers.rename(columns={\"Resource_Usage\": resource_label})\n",
    "    \n",
    "    \n",
    "    #print(\"Upper outliers: \")\n",
    "    #display(upper_outliers)\n",
    "    if  upper_outliers.empty:\n",
    "        upper_outliers = upper_outliers.append({resource_label: \"None\", \"Shard_Index\": \"None\"}, ignore_index=True)\n",
    "\n",
    "\n",
    "    #print(\"Lower outliers: \")\n",
    "    #display(lower_outliers)\n",
    "    if  lower_outliers.empty:\n",
    "        lower_outliers = lower_outliers.append({resource_label: \"None\", \"Shard_Index\": \"None\"}, ignore_index=True)\n",
    "\n",
    "    #Get Column names from pandas datafram\n",
    "    Columns = [TableColumn(field=Ci, title=Ci) for Ci in upper_outliers.columns] # bokeh columns\n",
    "    \n",
    "    #Create bokeh datatables using pandas dataframe and column names\n",
    "    upper_table = DataTable(columns=Columns, source=ColumnDataSource(upper_outliers)) # bokeh table\n",
    "    lower_table = DataTable(columns=Columns, source=ColumnDataSource(lower_outliers)) # bokeh table\n",
    "\n",
    "    #table title\n",
    "    upper_div = Div(text=\"<h3>Upper Outliers</h3>\",width=200, height=20)\n",
    "    lower_div = Div(text=\"<h3>Lower Outliers</h3>\",width=200, height=20)\n",
    "    \n",
    "        \n",
    "    #return upper_outliers, lower_outliers\n",
    "    return upper_div, upper_table, lower_div, lower_table\n",
    "    #return upper_table, lower_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_nan(input_dict):\n",
    "    # functional\n",
    "    clean_dict = filter(lambda k: not isnan(input_dict[k]), input_dict)\n",
    "    # dict comprehension\n",
    "    clean_dict = {k: input_dict[k] for k in input_dict if not isnan(input_dict[k])}\n",
    "    return clean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_1_metric(input_dict, title, y_label, x_label):\n",
    "    x = np.array((list(input_dict.keys())))\n",
    "    y = list(input_dict.values())\n",
    "    o=get_outliers(x, y, y_label)\n",
    "    p1=plot_violin(x, y, title, y_label, x_label)\n",
    "    p2=plot_bar(x, y, title, y_label, x_label)\n",
    "    return o[0], o[1], o[2], o[3], p1, p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task Shard summary\n",
    "\n",
    "The next cell will plot summary on a particular task, assuming that the task is shard-ed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shard_summary(df_input, task_name_input, workflow_id):\n",
    "\n",
    "    #Removes shards with null in columns being measured.  \n",
    "    df_droped_na = df_input.metrics_runtime.dropna(subset=['meta_duration_sec', 'metrics_disk_used_gb', 'metrics_mem_used_gb', 'metrics_mem_used_gb', 'metrics_cpu_used_percent'])\n",
    "    \n",
    "    #put dataframe into and array\n",
    "    summary_shards = df_droped_na.runtime_shard.loc[(df_droped_na['runtime_task_call_name'] == task_name)].unique()\n",
    "\n",
    "    #For each element in sereas get the average cpu, max cpu, max mem, max disk usage from monitoring datafram put in a dict\n",
    "    average_cpu_per_shard_dict = {}\n",
    "    max_cpu_per_shard_dict = {}\n",
    "    max_memory_per_shard_dict = {}\n",
    "    max_disk_per_shard_dict = {}\n",
    "    duration_per_shard_dict = {}\n",
    "    #for shard in summary_shards[0:99]: #used to test code on 100 shards\n",
    "    for shard in summary_shards:\n",
    "        #create dataframe for a given task name and shard\n",
    "        df_summary_shard = df_input.metrics_runtime.loc[(df_input.metrics_runtime['runtime_task_call_name'] == task_name_input) & (df_input.metrics_runtime['runtime_shard'] == shard)]\n",
    "\n",
    "        cpu_time_mean = df_summary_shard.metrics_cpu_used_percent.apply(mean_of_string)\n",
    "\n",
    "        average_cpu_per_shard_dict[str(shard)] = cpu_time_mean.mean()\n",
    "        max_cpu_per_shard_dict[str(shard)] = cpu_time_mean.max()\n",
    "\n",
    "        max_memory_per_shard_dict[str(shard)] = df_summary_shard.metrics_mem_used_gb.max()\n",
    "\n",
    "        max_disk_per_shard_dict[str(shard)] = df_summary_shard.metrics_disk_used_gb.apply(get_1st_disk_usage).max()\n",
    "\n",
    "        duration_per_shard_dict[str(shard)] = df_summary_shard['meta_duration_sec'].iloc[0]\n",
    "\n",
    "    #Removes nan values from dict\n",
    "    average_cpu_per_shard_clean_dict = remove_nan(average_cpu_per_shard_dict)\n",
    "    max_cpu_per_shard_clean_dict = remove_nan(max_cpu_per_shard_dict)\n",
    "    max_memory_per_shard_clean_dict = remove_nan(max_memory_per_shard_dict)\n",
    "    max_disk_per_shard_clean_dict = remove_nan(max_disk_per_shard_dict)\n",
    "    duration_per_shard_clean_dict = remove_nan(duration_per_shard_dict)\n",
    "\n",
    "    #Sort resource dict by value\n",
    "    average_cpu_per_shard_sorted_dict = {k: v for k, v in sorted(average_cpu_per_shard_clean_dict.items(), reverse = True, key=lambda item: item[1])}  \n",
    "    max_cpu_per_shard_sorted_dict = {k: v for k, v in sorted(max_cpu_per_shard_clean_dict.items(), reverse = True, key=lambda item: item[1])}  \n",
    "    max_memory_per_shard_sorted_dict = {k: v for k, v in sorted(max_memory_per_shard_clean_dict.items(), reverse = True, key=lambda item: item[1])}  \n",
    "    max_disk_per_shard_sorted_dict = {k: v for k, v in sorted(max_disk_per_shard_clean_dict.items(), reverse = True, key=lambda item: item[1])} \n",
    "    duration_per_shard_sorted_dict = {k: v for k, v in sorted(duration_per_shard_clean_dict.items(), reverse = True, key=lambda item: item[1])} \n",
    "\n",
    "    output_file(\"{}_{}_shard_summary.html\".format(PARENT_WORKFLOW_ID, task_name_input)) \n",
    "    \n",
    "    p_cpu_a = plot_1_metric(average_cpu_per_shard_sorted_dict, \"Average CPU Usage Per Shard\", \"CPU Usage\",\"shards\")\n",
    "    p_cpu_m = plot_1_metric(max_cpu_per_shard_sorted_dict, \"Max CPU Usage Per Shard\", \"CPU Usage\",\"shards\")\n",
    "    p_mem_m = plot_1_metric(max_memory_per_shard_sorted_dict, \"Max Memory Usage Per Shard\", \"Memory Usage GB\",\"shards\")\n",
    "    p_dis_m = plot_1_metric(max_disk_per_shard_sorted_dict, \"Max Disk Usage Per Shard\", \"Disk Usage GB\",\"shards\")\n",
    "    p_dur = plot_1_metric(duration_per_shard_sorted_dict, \"Time Duration Per Shard\", \"Seconds\",\"shards\")\n",
    "    Title_div = Div(text=\"<h1>{} {} Task Shard Summary</h2>\".format(workflow_id, task_name),width=1200, height=25)\n",
    "\n",
    "    # Writes to html file all the generated plots and tables for summary shard\n",
    "    show(layout([\n",
    "                [Title_div],\n",
    "                [Div(text=\"<h2>{} Average CPU Usage Per Shard</h2>\".format(task_name),width=600, height=25)],\n",
    "                [p_cpu_a[0], p_cpu_a[2]],\n",
    "                [p_cpu_a[1], p_cpu_a[3]],\n",
    "                [p_cpu_a[5], Div(text=\"\",width=50, height=25)],\n",
    "\n",
    "                [Div(text=\"<h2>{} Max CPU Usage Per Shard</h2>\".format(task_name),width=600, height=25)],\n",
    "                [p_cpu_m[0], p_cpu_m[2]],\n",
    "                [p_cpu_m[1], p_cpu_m[3]],\n",
    "                [p_cpu_m[5], Div(text=\"\",width=50, height=25)],\n",
    "\n",
    "                [Div(text=\"<h2>{} Max Memory Usage Per Shard</h2>\".format(task_name),width=600, height=25)],\n",
    "                [p_mem_m[0], p_mem_m[2]],\n",
    "                [p_mem_m[1], p_mem_m[3]],\n",
    "                [p_mem_m[5], Div(text=\"\",width=50, height=25)],\n",
    "\n",
    "                [Div(text=\"<h2>{} Max Disk Usage Per Shard</h2>\".format(task_name),width=600, height=25)],\n",
    "                [p_dis_m[0], p_dis_m[2]],\n",
    "                [p_dis_m[1], p_dis_m[3]],\n",
    "                [p_dis_m[5], Div(text=\"\",width=50, height=25)],\n",
    "\n",
    "                [Div(text=\"<h2>{} Time Duration Usage Per Shard</h2>\".format(task_name),width=600, height=25)],\n",
    "                [p_dur[0], p_dur[2]],\n",
    "                [p_dur[1], p_dur[3]],\n",
    "                [p_dur[5]]\n",
    "                ], sizing_mode='scale_width' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task Detailed Summary\n",
    "This for loop will iterate over each task in the workflow, if the task has more than one shard than it will execute the shard summary definition above createing a task summary html and move on to the next task. If the task has only 1 shard than it will create the detailed resource usage pdf file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saves plots into the following pdf\n",
    "with PdfPages(PARENT_WORKFLOW_ID + '_resource_monitoring.pdf') as pdf:\n",
    "\n",
    "    for task_name in TaskNames:\n",
    "        # Gets the all shards for a given task name\n",
    "        shards = df_monitoring.metadata_runtime.meta_shard.loc[(df_monitoring.metadata_runtime['meta_task_call_name'] == task_name)]\n",
    "        shards = shards.sort_values().unique()\n",
    "        \n",
    "        # If shard counts is greater than 10 then gets 10 longest running shards for a given task name\n",
    "        max_shards=2\n",
    "        if len(shards) >= max_shards:\n",
    "            #create and sort meta table by duration\n",
    "            df_monitoring_task = df_monitoring.metadata_runtime.loc[(df_monitoring.metadata_runtime['meta_task_call_name'] == task_name)]\n",
    "            \n",
    "            #removes duplicate shards\n",
    "            df_monitoring_task_uniqueShard = df_monitoring_task.drop_duplicates(subset =\"meta_shard\")\n",
    "            df_monitoring_task_sorted_duration = df_monitoring_task_uniqueShard.sort_values(by='meta_duration_sec', ascending=False)\n",
    "            \n",
    "            #replace all shards in varaible shards with the first 50 of the sorted duration table\n",
    "            shards = df_monitoring_task_sorted_duration.meta_shard.head(max_shards)\n",
    "            \n",
    "            #Get shard summary\n",
    "            shard_summary(df_monitoring, task_name, PARENT_WORKFLOW_ID)\n",
    "\n",
    "        # Create detailed resource usage plots\n",
    "        if len(shards) < 2:\n",
    "            for shard in shards:\n",
    "                \n",
    "                # For size and style of plots\n",
    "                plt.rcParams[\"figure.figsize\"] = (15, 20)\n",
    "                sns.set(style=\"whitegrid\")\n",
    "\n",
    "                df_monitoring_task_shard = df_monitoring.metrics_runtime.loc[(df_monitoring.metrics_runtime['runtime_task_call_name'] == task_name) & (df_monitoring.metrics_runtime['runtime_shard'] == shard)]\n",
    "                df_monitoring_metadata_runtime_task_shard = df_monitoring.metadata_runtime.loc[(df_monitoring.metadata_runtime['runtime_task_call_name'] == task_name) & (df_monitoring.metadata_runtime['runtime_shard'] == shard)]\n",
    "                df_monitoring_task_shard = df_monitoring_task_shard.sort_values(by='metrics_timestamp')\n",
    "\n",
    "                task_shard_meta_duration = df_monitoring_metadata_runtime_task_shard.meta_duration_sec.iloc[0]\n",
    "                max_datetime = max(df_monitoring_task_shard['metrics_timestamp'])\n",
    "                min_datetime = min(df_monitoring_task_shard['metrics_timestamp'])\n",
    "                task_shard_duration = round(datetime.timedelta.total_seconds(max_datetime - min_datetime))\n",
    "\n",
    "                # create an array for list coloumns\n",
    "                cpu_used_percent_array = [np.asarray(x).mean() for x in df_monitoring_task_shard.metrics_cpu_used_percent]\n",
    "                disk_used_gb_array = [np.asarray(x).max() for x in df_monitoring_task_shard.metrics_disk_used_gb]\n",
    "                disk_read_iops_array = [np.asarray(x).max() for x in df_monitoring_task_shard.metrics_disk_read_iops]\n",
    "                disk_write_iops_array = [np.asarray(x).max() for x in df_monitoring_task_shard.metrics_disk_write_iops]\n",
    "\n",
    "                runtime_list= df_monitoring_metadata_runtime_task_shard.iloc[0].at['meta_inputs']\n",
    "                runtime_dic={}\n",
    "                for i, element in enumerate(runtime_list):\n",
    "                    if re.search(\"default_attr\", element[\"key\"]) or re.search(\"runtime_attr_override\", element[\"key\"]):\n",
    "                        continue\n",
    "                    else:\n",
    "                        k = element[\"key\"].replace(\"[\", \"\").replace(\"]\", \"\").replace(\"runtime_attr\", \"\").replace(\"\\\"\", \"\", 2)\n",
    "                        v = element[\"value\"]\n",
    "                        runtime_dic[k]=v\n",
    "\n",
    "                plt.subplot(5, 1, 1)\n",
    "                plt.title(\"Task Name: \" + task_name + \" Shard: \" + str(shard) + \" Duration: \" +  str(task_shard_duration), fontsize=20)\n",
    "                plt.plot(df_monitoring_task_shard.metrics_timestamp.astype('O'), cpu_used_percent_array, label='CPU Used')\n",
    "                plt.plot([], [], ' ', label='Obtained CPU Cores: {}' .format(df_monitoring_metadata_runtime_task_shard.iloc[0].at['meta_cpu']))\n",
    "                plt.plot([], [], ' ', label='Requested CPU Cores: {}' .format(round(float(runtime_dic[\"cpu_cores\"]))))\n",
    "                plt.legend(loc='upper center', bbox_to_anchor=(1.20, 0.8), shadow=True, ncol=1)\n",
    "                plt.ylabel('CPU Percentage Used')\n",
    "                plt.xlabel(\"Date Time\")\n",
    "                plt2 = plt.twiny()\n",
    "                plt2.set_xlim(0, task_shard_duration)\n",
    "                plt2.set_xlabel(\"Duration Time\")\n",
    "                plt.grid(True)\n",
    "\n",
    "                plt.subplot(5, 1, 2)\n",
    "                plt.plot(df_monitoring_task_shard.metrics_timestamp.astype('O'), df_monitoring_task_shard.metrics_mem_used_gb, label='Memory Used')\n",
    "                plt.axhline(y=df_monitoring_metadata_runtime_task_shard.iloc[0].at['meta_mem_total_gb'], color='r', label='Max Memory GB: %.2f' %(df_monitoring_metadata_runtime_task_shard.iloc[0].at['meta_mem_total_gb']))\n",
    "                plt.plot([], [], ' ', label='Requested Memory GB: {}' .format(round(float(runtime_dic[\"mem_gb\"]), 2)))\n",
    "                plt.legend(loc='upper center', bbox_to_anchor=(1.20, 0.8), shadow=True, ncol=1)\n",
    "                plt.ylabel('Memory Used in GB')\n",
    "                plt.xlabel(\"Date Time\")\n",
    "                plt2 = plt.twiny()\n",
    "                plt2.set_xlim(0, task_shard_duration)\n",
    "                plt2.set_xlabel(\"Duration Time\")\n",
    "                plt.grid(True)\n",
    "\n",
    "                plt.subplot(5, 1, 3)\n",
    "                plt.plot(df_monitoring_task_shard.metrics_timestamp.astype('O'), disk_used_gb_array, label='Disk Used')\n",
    "                plt.axhline(y=max(df_monitoring_metadata_runtime_task_shard.iloc[0].at['meta_disk_total_gb']), color='r', label='Max Disksize GB: %.2f' %(max(df_monitoring_metadata_runtime_task_shard.iloc[0].at['meta_disk_total_gb'])))\n",
    "                plt.plot([], [], ' ', label='Requested Disksize GB: {}' .format(round(float(runtime_dic[\"disk_gb\"]), 2)))\n",
    "                plt.legend(loc='upper center', bbox_to_anchor=(1.20, 0.8), shadow=True, ncol=1)\n",
    "                plt.ylabel('Diskspace Used in GB')\n",
    "                plt.xlabel(\"Date Time\")\n",
    "                plt2 = plt.twiny()\n",
    "                plt2.set_xlim(0, task_shard_duration)\n",
    "                plt2.set_xlabel(\"Duration Time\")\n",
    "                plt.grid(True)\n",
    "\n",
    "                plt.subplot(5, 1, 4)\n",
    "                plt.plot(df_monitoring_task_shard.metrics_timestamp.astype('O'), disk_read_iops_array)\n",
    "                plt.ylabel('Disk Read IOps')\n",
    "                plt.xlabel(\"Date Time\")\n",
    "                plt2 = plt.twiny()\n",
    "                plt2.set_xlim(0, task_shard_duration)\n",
    "                plt2.set_xlabel(\"Duration Time\")\n",
    "                plt.grid(True)\n",
    "\n",
    "                plt.subplot(5, 1, 5)\n",
    "                plt.plot(df_monitoring_task_shard.metrics_timestamp.astype('O'), disk_write_iops_array)\n",
    "                plt.ylabel('Disk Write_IOps')\n",
    "                plt.xlabel(\"Date Time\")\n",
    "                plt2 = plt.twiny()\n",
    "                plt2.set_xlim(0, task_shard_duration)\n",
    "                plt2.set_xlabel(\"Duration Time\")\n",
    "                plt.grid(True)\n",
    "\n",
    "                plt.subplots_adjust(hspace = 0.5)\n",
    "                pdf.savefig(bbox_inches='tight', pad_inches=0.5)\n",
    "                plt.show()\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save files to a Google Bucket\n",
    "Here we will be saving the file produced by the notebook into an a google bucket. You'll need to set the google bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Requires that user (or Terra user proxy) has edit access to destination bucket\n",
    "OUTPUT_BUCKET = \"gs://broad-dsde-methods-bshifaw/monitoring-plots/test/\"\n",
    "WORKFLOW_NAME = df_monitoring.metadata_runtime.iloc[0].at['meta_workflow_name'] \n",
    "\n",
    "!gsutil cp ./{PARENT_WORKFLOW_ID}_resource_monitoring.pdf {OUTPUT_BUCKET}\n",
    "!gsutil cp ./{PARENT_WORKFLOW_ID}*_shard_summary.html {OUTPUT_BUCKET}\n",
    "!gsutil cp ./{PARENT_WORKFLOW_ID}_workflow_summary.html {OUTPUT_BUCKET}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
